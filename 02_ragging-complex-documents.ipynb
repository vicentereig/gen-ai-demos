{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cf794307fd67b830"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Parsing and Indexing complex documents is crucial to play to LLMs strengths. LlamaIndex has a service called LlamaParse with a generous free tier. Also this library (which has a $ option) can get your far: `pymupdf4llm`\n",
    "\n",
    "> TL;DR chunking strategies - you want to provide the LLM with enough context to answer questions on complex documents. Assume a with a table breaking down your fuel expenses for last year and you wanted to predict the answer for : \"how much did I spend on september 2024\"? Providing the markdown version of the table helps a lot. Not perfect tho! but helps.\n",
    "\n",
    "## Contextual retrieval through better chunking\n",
    "There are a few quick wins and high ROI tactics compared to other knowledge based retrieval strategies that are harder and more expensive to deploy (graphrag, lightrag):\n",
    "- In addition to the basic chunking, you can keep themes and ideas following the natural flow of the doc. Page-long chunks to enhance the generation.\n",
    "- Since you have are dealing with a markdown doc, chunk it by sections too. That's easy to parse with a md parser.\n",
    "- Dump the PDFs to markdown especially to keep tables so LLMs can answer questions in those tables during Generation.\n",
    "- Leverage lightweight doc and page summaries using classic ML algorithms instead of LLMs for scalability and costs.\n",
    "- Remember that indexing docs for RAG is pretty much ETL, so cleaning up the markdown contents plays to the LLM's strengths.\n",
    "- Watch out on how to do similarity search on pages and sections to account for max input length. i.e. I am using SentenceTransformer('intfloat/multilingual-e5-large') and I make sure my chunks are under 512 tokens."
   ],
   "id": "655658d2a0e2015a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
